{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T06:02:50.362195Z",
     "start_time": "2019-04-19T06:02:50.357772Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install twython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T06:02:50.852875Z",
     "start_time": "2019-04-19T06:02:50.373993Z"
    }
   },
   "outputs": [],
   "source": [
    "from twython import Twython\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import time\n",
    "import yaml\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T06:02:51.377117Z",
     "start_time": "2019-04-19T06:02:50.953545Z"
    }
   },
   "outputs": [],
   "source": [
    "APP_KEY = 'OumzA854PAnWwA8VNjwZ6O1T1'\n",
    "APP_SECRET = \"aHWN7hVHFYGTJIqLG6d1sUgT2tzelmB7LNxtQjJz0RkmLDIFGW\"\n",
    "\n",
    "twitter = Twython(APP_KEY, APP_SECRET, oauth_version=2)\n",
    "ACCESS_TOKEN = twitter.obtain_access_token()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T06:02:53.025026Z",
     "start_time": "2019-04-19T06:02:53.019619Z"
    }
   },
   "outputs": [],
   "source": [
    "twitter = Twython(APP_KEY, access_token=ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T21:51:04.669226Z",
     "start_time": "2019-04-14T21:51:04.616511Z"
    }
   },
   "outputs": [],
   "source": [
    "locationsTemp=[\"chennai\",\"delhi\",\"india\",\"ahmedabad\",\"gujarat\",\"tamil\",\"jammu\",\"srinagar\",\"imphal\",\"lucknow\",\n",
    "                \"bengaluru\",\"bangalore\",\"bathinda\",\"chandigarh\",\"ludhiana\",\"amritsar\",\"punjab\",\"arunachal\",\"assam\",\n",
    "                \"kolkata\",\"westbengal\",\"kerala\",\"karnataka\",\"andhra\",\"telangana\",\"hyderabad\",\"madhya\",\"uttar\",\n",
    "                \"maharashtra\",\"haryana\",'Jammu','Srinagar','Delhi-NewDelhi','Bathinda','Dehradun','Chandigarh',\n",
    "                'Ludhiana','Amritsar','Imphal','Lucknow','Jalandhar','Kolkata','Guwahati','Chennai','Patiala',\n",
    "                'Bhubaneswar','Bengaluru','Patna','Jaipur','Coimbatore','Hyderabad','Ranchi','Thiruvananthapuram',\n",
    "                'Shimla','Sangrur','Ahmedabad','Karnal','Pulwama','Puducherry','Gurgaon','Agartala','Madurai',\n",
    "                'Tiruchirappalli','Bangkok','Salem']\n",
    "\n",
    "locations = set()\n",
    "for location in locationsTemp:\n",
    "    locations.add(location.lower())\n",
    "locations = pd.DataFrame(list(locations))\n",
    "locations.columns = [\"Locations\"]\n",
    "locations.to_csv(\"Locations of Interest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T21:51:06.268607Z",
     "start_time": "2019-04-14T21:51:06.262178Z"
    }
   },
   "outputs": [],
   "source": [
    "keywords = ['protest','protests','riot','riots','violence','unrest','clash','bandh','issue','rally','demonstration','election','polls','attac']\n",
    "keywords = pd.DataFrame(keywords)\n",
    "keywords.columns = [\"Keywords\"]\n",
    "keywords.to_csv(\"Keywords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T21:51:06.983114Z",
     "start_time": "2019-04-14T21:51:06.972203Z"
    }
   },
   "outputs": [],
   "source": [
    "locations = pd.read_csv(\"Locations of Interest.csv\", index_col=0)\n",
    "keywords = pd.read_csv(\"Keywords.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T21:51:08.051507Z",
     "start_time": "2019-04-14T21:51:08.047252Z"
    }
   },
   "outputs": [],
   "source": [
    "keywordsQuery = ''.join(map(str, [keyword+\" OR \" for keyword in list(keywords['Keywords'])]))[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T21:51:09.052260Z",
     "start_time": "2019-04-14T21:51:09.048068Z"
    }
   },
   "outputs": [],
   "source": [
    "start = 0\n",
    "to_return = []\n",
    "loc_list =locations[\"Locations\"].values.tolist()\n",
    "len_loc = len(loc_list) // 5 + 1\n",
    "for i in range(5):\n",
    "    to_return.append(loc_list[start:start+len_loc])\n",
    "    start+=len_loc\n",
    "    \n",
    "locationQueries=[]\n",
    "for row in to_return:\n",
    "    locationQueries.append(''.join(map(str, [location+\" OR \" for location in row]))[:-4])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locations Queries\n",
      "\n",
      " ['chandigarh OR delhi-newdelhi OR thiruvananthapuram OR shimla OR tiruchirappalli OR patna OR agartala OR bhubaneswar OR patiala OR bathinda OR bangkok', 'jaipur OR chennai OR tamil OR jammu OR karnataka OR ahmedabad OR andhra OR jalandhar OR uttar OR arunachal OR pulwama', 'guwahati OR india OR haryana OR dehradun OR bangalore OR kolkata OR telangana OR assam OR lucknow OR coimbatore OR karnal', 'salem OR delhi OR srinagar OR gujarat OR westbengal OR sangrur OR kerala OR ludhiana OR madhya OR amritsar OR hyderabad', 'gurgaon OR punjab OR bengaluru OR ranchi OR madurai OR maharashtra OR puducherry OR imphal'] \n",
      "\n",
      "Keywords Query\n",
      "\n",
      " protest OR protests OR riot OR riots OR violence OR unrest OR clash OR bandh OR issue OR rally OR demonstration OR election OR polls OR attac\n"
     ]
    }
   ],
   "source": [
    "print(\"Locations Queries\\n\\n\", locationQueries,\"\\n\")\n",
    "print(\"Keywords Query\\n\\n\", keywordsQuery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: generator 'Twython.cursor' raised StopIteration\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10000\n",
      "Progress: 20000\n",
      "Progress: 30000\n",
      "Progress: 40000\n",
      "Thread sleep\n",
      "Progress: 0\n",
      "Progress: 10000\n"
     ]
    }
   ],
   "source": [
    "date = dt.datetime.now()\n",
    "cnt = 0\n",
    "tweetList = []\n",
    "for locationQuery in locationQueries:\n",
    "    tweets = twitter.cursor(twitter.search, q=keywordsQuery + ' (' +locationQuery + ') -filter:retweets', count=100, tweet_mode = \"extended\")\n",
    "    for item in tweets:\n",
    "        if (cnt%10000 == 0):\n",
    "            print(\"Progress: \"+str(cnt))\n",
    "        tweetList.append(item)\n",
    "        cnt+=1\n",
    "        if cnt > 40000:\n",
    "            print(\"Thread sleep\")\n",
    "            time.sleep(60*15+5)\n",
    "            cnt = 0\n",
    "tweetsDF = pd.DataFrame(tweetList)\n",
    "tweetsDF.to_csv(\"tweets_collected_\"+str(date.day)+str(date.strftime(\"%m\"))+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (4,9,32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\Dan\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (4,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "tweetsDF1 = pd.read_csv(\"tweets_collected_2704.csv\", dtype={'id':object})\n",
    "tweetsDF2 = pd.read_csv(\"tweets_collected_505.csv\", dtype={'id':object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.concat([tweetsDF1, tweetsDF2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 10000\n",
      "Progress: 20000\n",
      "Progress: 30000\n",
      "Progress: 40000\n",
      "Progress: 10000\n",
      "Progress: 20000\n",
      "Progress: 30000\n",
      "Progress: 40000\n"
     ]
    }
   ],
   "source": [
    "cnt = 1\n",
    "rowInd = 1\n",
    "tempList = []\n",
    "tweetList = []\n",
    "tweetsDfs = []\n",
    "date = dt.datetime.now()\n",
    "for index, row in tweets.iterrows():\n",
    "    tempList.append(row[\"id\"])\n",
    "    if cnt%100 == 0:\n",
    "        try:\n",
    "            tweetList.extend(twitter.lookup_status(id=tempList, tweet_mode = \"extended\"))\n",
    "            tempList = []\n",
    "        except:\n",
    "            print(\"Succesful till: \"+cnt)\n",
    "    if (cnt%10000 == 0):\n",
    "        print(\"Progress: \"+str(cnt))\n",
    "        if cnt >= 40000:\n",
    "            tweetsDfs.append(pd.DataFrame(tweetList))\n",
    "#             tweetsDf.to_csv(\"Tweets3Weeks\"+str(date.day)+str(date.strftime(\"%m\"))+\"_\"+str(rowInd)+\".csv\")\n",
    "            tweetList = []\n",
    "            rowInd+=1\n",
    "#             print(\"Thread sleep\")\n",
    "#             time.sleep(60*15+5)\n",
    "            cnt = 0\n",
    "    cnt+=1\n",
    "tweetList.extend(twitter.lookup_status(id=tempList, tweet_mode = \"extended\"))\n",
    "tweetsDfs.append(pd.DataFrame(tweetList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T21:54:24.230646Z",
     "start_time": "2019-04-14T21:54:18.259984Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "tweetsDF = pd.concat(tweetsDfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36298, 33)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweetsDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsDF.index = np.arange(len(tweetsDF))\n",
    "tweetsDF.to_json('Tweets060519.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T22:40:37.210288Z",
     "start_time": "2019-04-14T22:40:37.202088Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm_notebook as tqdm\n",
    "def get_features(row):\n",
    "    row[\"userlocation\"] = row[\"user\"][\"location\"]\n",
    "    row[\"username\"] = row[\"user\"][\"name\"]\n",
    "    row[\"userscreen_name\"] = row[\"user\"][\"screen_name\"]\n",
    "    row[\"userdescription\"] = row[\"user\"][\"description\"]\n",
    "    row[\"userfollowers_count\"] = row[\"user\"][\"followers_count\"]\n",
    "    row[\"userfriends_count\"] = row[\"user\"][\"friends_count\"]\n",
    "    row[\"userlisted_count\"] = row[\"user\"][\"listed_count\"]\n",
    "    row[\"userfavourites_count\"] = row[\"user\"][\"favourites_count\"]\n",
    "    row[\"userverified\"] = row[\"user\"][\"verified\"]\n",
    "    row[\"userstatuses_count\"] = row[\"user\"][\"statuses_count\"]\n",
    "    row[\"userfollowing\"] = row[\"user\"][\"following\"]\n",
    "    row[\"userfollow_request_sent\"] = row[\"user\"][\"follow_request_sent\"]\n",
    "    row[\"usercontributors_enabled\"] = row[\"user\"][\"contributors_enabled\"]\n",
    "    sepr =  \"\" \n",
    "    l = []\n",
    "    for location in locations['Locations']: \n",
    "        if (location in str(row[\"full_text\"]).lower()):\n",
    "            l.append(location)\n",
    "    row[\"extracted_location\"] = ','.join(l)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T23:29:58.927542Z",
     "start_time": "2019-04-14T22:41:45.855742Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_data = tweetsDF.apply(get_features, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.index = np.arange(len(processed_data))\n",
    "processed_data.to_json('Tweets_latest.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T06:09:33.787860Z",
     "start_time": "2019-04-19T06:09:33.776473Z"
    }
   },
   "outputs": [],
   "source": [
    "acledLocations = ['Jammu',\n",
    " 'Srinagar',\n",
    " 'Delhi-New Delhi',\n",
    " 'Bathinda',\n",
    " 'Dehradun',\n",
    " 'Chandigarh',\n",
    " 'Ludhiana',\n",
    " 'Amritsar',\n",
    " 'Imphal',\n",
    " 'Lucknow',\n",
    " 'Jalandhar',\n",
    " 'Kolkata',\n",
    " 'Guwahati',\n",
    " 'Chennai',\n",
    " 'Patiala',\n",
    " 'Bhubaneswar',\n",
    " 'Bengaluru',\n",
    " 'Patna',\n",
    " 'Jaipur',\n",
    " 'Coimbatore',\n",
    " 'Hyderabad',\n",
    " 'Ranchi',\n",
    " 'Thiruvananthapuram',\n",
    " 'Shimla',\n",
    " 'Sangrur',\n",
    " 'Ahmedabad',\n",
    " 'Karnal',\n",
    " 'Pulwama',\n",
    " 'Puducherry',\n",
    " 'Gurgaon',\n",
    " 'Agartala',\n",
    " 'Madurai',\n",
    " 'Tiruchirappalli',\n",
    " 'Bangkok',\n",
    " 'Salem','India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T06:09:45.271947Z",
     "start_time": "2019-04-19T06:09:45.245655Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_locations(row):\n",
    "    dfrow_list = []\n",
    "    for location in acledLocations: \n",
    "        tempLocation = location\n",
    "        tempLocation2 = location\n",
    "        if (tempLocation == \"Delhi-New Delhi\"):\n",
    "            tempLocation = \"delhi\"\n",
    "        elif (tempLocation == \"Bengaluru\"):\n",
    "            tempLocation = \"bangalore\"\n",
    "            tempLocation2 = \"karnataka\"\n",
    "        elif (tempLocation == \"Kolkata\"):\n",
    "            tempLocation = \"west bengal\"\n",
    "        elif (tempLocation == \"Guwahati\"):\n",
    "            tempLocation = \"assam\"\n",
    "        elif (tempLocation in (\"Lucknow\", \"Dehradun\")):\n",
    "            tempLocation = \"uttar\"\n",
    "        elif (tempLocation in (\"Sangrur\", \"Ludhiana\", \"Amritsar\", \"Chandigarh\", \"Bathinda\", \"Jalandhar\", \"Patiala\")):\n",
    "            tempLocation = \"punjab\"\n",
    "        elif (tempLocation in (\"Karnal\", \"Gurgaon\", \"Chandigarh\")):\n",
    "            tempLocation2 = \"haryana\"\n",
    "        elif (tempLocation == \"Pulwama\"):\n",
    "            tempLocation2 = \"jammu\"\n",
    "        elif (tempLocation == \"Ahmedabad\"):\n",
    "            tempLocation = \"gujarat\"\n",
    "        elif (tempLocation in (\"Chennai\", \"Coimbatore\", \"Madurai\", \"Tiruchirappalli\", \"Salem\")):\n",
    "            tempLocation = \"tamil\"\n",
    "        elif (tempLocation in (\"Imphal\", \"Agartala\")):\n",
    "            tempLocation = \"arunachal\"\n",
    "        elif (tempLocation == \"Hyderabad\"):\n",
    "            tempLocation = \"andhra\"\n",
    "            tempLocation2 = \"telangana\"\n",
    "        elif (tempLocation == \"Thiruvananthapuram\"):\n",
    "            tempLocation = \"kerala\"\n",
    "        if (tempLocation.lower() in row[\"extracted_location\"] or location.lower() in row[\"extracted_location\"] or tempLocation2 in row[\"extracted_location\"]):\n",
    "            row[\"finallocation\"] = location\n",
    "            dfrow_list.append(row.copy())\n",
    "#     print(row)\n",
    "    return pd.DataFrame(dfrow_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posssed_df = pd.concat(processed_data.apply(generate_locations, axis = 1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"../../../data/TweetsConsolidated.json\")\n",
    "df = pd.concat([posssed_df, df])\n",
    "df.index = np.arange(len(df))\n",
    "df.to_json(\"../../../data/TweetsConsolidated.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
